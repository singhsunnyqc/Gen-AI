{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Hands-On with Generative AI Assignment\n",
        "\n",
        "Here you will gain hands-on experience working with GPT language models via the OpenAI API. Specifically, you will:\n",
        "1. Create an OpenAI account and obtain an API key.\n",
        "2. Try generating outputs from several different models available via the API.\n",
        "3. Gain a first exposure to prompt engineering by experimenting with using multiple prompts for a given task."
      ],
      "metadata": {
        "id": "nx0qiGWO7qWV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Problem 1\n",
        "\n",
        "Create an [OpenAI account](https://openai.com/index/openai-api), then generate an API key."
      ],
      "metadata": {
        "id": "pVACWFAT7_k6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Solution\n",
        "\n",
        "After logging into your account, go to [https://platform.openai.com/api-keys](https://platform.openai.com/api-keys). Click the \"Create new secret key\" button to create a new API key. Copy your newly created API key upon creation."
      ],
      "metadata": {
        "id": "hclHhBFFofjB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Problem 2\n",
        "\n",
        "Use the OpenAI API to produce responses to a given prompt using two different models. First use the GPT-3.5 Turbo model to evaluate the prompt, then use the GPT-4 Turbo model to evaluate the same prompt.\n",
        "\n",
        "For your prompt, try asking the models to perform the following task which requires a bit of reasoning to solve:\n",
        "```\n",
        "Andrew is free from 11 am to 3 pm, Joanne is free from noon to 2 pm and then 3:30 pm to 5 pm.\n",
        "Hannah is available at noon for half an hour, and then 4 pm to 6 pm.\n",
        "What are some options for start times for a 30 minute meeting for Andrew, Hannah, and Joanne?\n",
        "```\n",
        "Compare the quality of the outputs that are obtained from the two different models."
      ],
      "metadata": {
        "id": "ycWJVTEyoibf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Solution\n",
        "\n",
        "To complete this problem we will need to perform the following steps:\n",
        "1. Install the `openai` Python package.\n",
        "2. Create an OpenAI client using your API key. In these solutions we load our key from Google drive to avoid hard-coding the API key in our solution.\n",
        "3. Pass the prompt above to the `chat.completions` API using the `gpt-3.5-turbo` model.\n",
        "4. Pass the prompt above to the `chat.completions` API using the `gpt-4-turbo` model.\n",
        "5. Compare the outputs obtained by both models."
      ],
      "metadata": {
        "id": "a6WBn6swqhHV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qp2JAR0-28Kt",
        "outputId": "db99e7a4-6633-45c1-d092-472372524598"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.30.1-py3-none-any.whl (320 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.6/320.6 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.30.1\n"
          ]
        }
      ],
      "source": [
        "# Install the openai package\n",
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import packages that you will use for accessing the OpenAI API\n",
        "import json\n",
        "from google.colab import drive\n",
        "from openai import OpenAI"
      ],
      "metadata": {
        "id": "qHqi4fZW3LL5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive.\n",
        "# We will get our OpenAI API key from a file that we stored in Google Drive.\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tiOTaZKz3j32",
        "outputId": "82fd7f51-aff7-4c13-c30e-d8ae8f6310b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read in API key\n",
        "with open(\"/content/gdrive/MyDrive/OpenAI/keys.json\", \"r\") as f:\n",
        "  api_key = json.loads(f.read())[\"api_key\"]"
      ],
      "metadata": {
        "id": "9wKV2nPO3Omo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "d0b2815c-4bc2-4c69-ad8f-adb81564c1dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/gdrive/MyDrive/OpenAI/keys.json'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-5a436ba5427a>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Read in API key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/gdrive/MyDrive/OpenAI/keys.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mapi_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msk\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mproj\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mbzpWDAEU6aAeXkyzwkn3T3BlbkFJ513yV7cpghmzuYfZYZ88\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/gdrive/MyDrive/OpenAI/keys.json'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an OpenAI client\n",
        "client = OpenAI(api_key=api_key)"
      ],
      "metadata": {
        "id": "9SJd5wNw3RJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generating response from gpt-3.5-turbo\n",
        "\n",
        "prompt = \"\"\"\n",
        "Andrew is free from 11 am to 3 pm, Joanne is free from noon to 2 pm and then 3:30 pm to 5 pm.\n",
        "Hannah is available at noon for half an hour, and then 4 pm to 6 pm.\n",
        "What are some options for start times for a 30 minute meeting for Andrew, Hannah, and Joanne?\n",
        "\"\"\"\n",
        "\n",
        "# Note the use of the \"temperature\" parameter...\n",
        "# ...this allows us to generate reproducable outputs\n",
        "openai_response = client.chat.completions.create(\n",
        "    model = 'gpt-3.5-turbo',\n",
        "    messages = [{'role': 'user', 'content': prompt}],\n",
        "    temperature = 0\n",
        ")\n",
        "\n",
        "# Print the response\n",
        "print(openai_response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3oPP_fX4VYP",
        "outputId": "131ccb6b-7f3f-42c9-a2ea-f8ad2e901e9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Some options for start times for a 30-minute meeting for Andrew, Hannah, and Joanne could be:\n",
            "\n",
            "- 12:00 pm (noon) - 12:30 pm: All three are available during this time slot.\n",
            "- 4:00 pm - 4:30 pm: Andrew and Hannah are available during this time slot.\n",
            "- 3:30 pm - 4:00 pm: Joanne and Hannah are available during this time slot.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now generating response from gpt-4-turbo\n",
        "openai_response = client.chat.completions.create(\n",
        "    model = 'gpt-4-turbo',\n",
        "    messages = [{'role': 'user', 'content': prompt}],\n",
        "    temperature = 0\n",
        ")\n",
        "\n",
        "# Print the response\n",
        "print(openai_response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRlgbQFPr0aX",
        "outputId": "7935d586-6dea-4aff-9859-21e9a29b085a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To find a suitable 30-minute meeting time for Andrew, Joanne, and Hannah, we need to look for overlapping times in their schedules. Here's a breakdown of their availability:\n",
            "\n",
            "- Andrew: 11 am to 3 pm\n",
            "- Joanne: 12 pm to 2 pm, 3:30 pm to 5 pm\n",
            "- Hannah: 12 pm to 12:30 pm, 4 pm to 6 pm\n",
            "\n",
            "The only overlapping time slot among all three individuals where a 30-minute meeting can be scheduled is from 12 pm to 12:30 pm. This is the only time when Andrew, Joanne, and Hannah are all available simultaneously. \n",
            "\n",
            "Therefore, the possible start time for a 30-minute meeting that includes Andrew, Joanne, and Hannah is:\n",
            "- 12:00 pm to 12:30 pm.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Comparison:** GPT-4 produced a higher quality output in this case. GPT-3.5 incorrectly states that 3:30 pm - 4:00 pm and 4:00 pm - 4:30 pm are options for the meeting. GPT-4 correctly reasons that 12-12:30 is the only feasible time."
      ],
      "metadata": {
        "id": "JT660kbsub7G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Problem 3\n",
        "Here you will see an example of how the prompting strategy can impact the quality of the output produced. In this problem you will again apply GPT-3.5 to the reasoning task from Problem 2. However, unlike in Problem 2, modify your prompt to include some general step-by-step instructions for solving a scheduling task like the one given. Can you produce a prompt that enables GPT-3.5 to arrive at a correct answer?"
      ],
      "metadata": {
        "id": "YLkPtSavLIQF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Solution\n",
        "\n",
        "We will modify our prompt by including the following general step-by-step instructions for solving a scheduling task:\n",
        "```\n",
        "You will be given a complex scheduling task below. Solve this task step-by-step by:\n",
        "- First identifying all time slots that each individual is available.\n",
        "- Then finding all time slots that all individuals are available.\n",
        "- Then selecting a time slot from among those where all individuals are available.\n",
        "```\n",
        "Note that these instructions are fairly generic, and don't provide any hints specific to the details of the given scheduling problem. However, this additional instruction appears sufficient to guide GPT-3.5 to a correct answer.\n"
      ],
      "metadata": {
        "id": "x5YFHsonu50b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generating response from gpt-3.5-turbo\n",
        "\n",
        "prompt = \"\"\"\n",
        "You will be given a complex scheduling task below. Solve this task step-by-step by:\n",
        "- First identifying all time slots that each individual is available.\n",
        "- Then finding all time slots that all individuals are available.\n",
        "- Then selecting a time slot from among those where all individuals are available.\n",
        "\n",
        "Task: Andrew is free from 11 am to 3 pm, Joanne is free from noon to 2 pm and then 3:30 pm to 5 pm.\n",
        "Hannah is available at noon for half an hour, and then 4 pm to 6 pm.\n",
        "What are some options for start times for a 30 minute meeting for Andrew, Hannah, and Joanne?\n",
        "\"\"\"\n",
        "\n",
        "openai_response = client.chat.completions.create(\n",
        "    model = 'gpt-3.5-turbo',\n",
        "    messages = [{'role': 'user', 'content': prompt}],\n",
        "    temperature = 0\n",
        ")\n",
        "\n",
        "# Print the response\n",
        "print(openai_response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHHImRTpvp7i",
        "outputId": "c7f1a46a-ef43-4af4-aa16-32f0e476eae4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First, let's identify all the time slots that each individual is available:\n",
            "\n",
            "Andrew: 11 am - 3 pm\n",
            "Joanne: 12 pm - 2 pm, 3:30 pm - 5 pm\n",
            "Hannah: 12 pm - 12:30 pm, 4 pm - 6 pm\n",
            "\n",
            "Next, let's find all time slots where all individuals are available:\n",
            "- The only overlapping time slot where all three individuals are available is from 12 pm to 12:30 pm.\n",
            "\n",
            "Therefore, the best option for a 30-minute meeting for Andrew, Hannah, and Joanne would be to schedule it at 12 pm.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BG7UhaPuv12t"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}