{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AN1HFqjm70X"
      },
      "source": [
        "In this notebook, we first implement a simple bi-gram model implementation, and train it on a tiny corpus. We then use this bi-gram model to generate texts. From this minimum bi-gram implementation, we should understand\n",
        "* How N-Gram performs language modeling, i.e. computing P(next_word | prev_grams)\n",
        "* How we can use P(next_word | prev_grams) values to generate texts.\n",
        "\n",
        "We then examine text generation from bi-gram and 4-gram models trained on IMDB movie review dataset. How well do our N-Gram model write movie reviews?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AUhiYdcAPtK-"
      },
      "outputs": [],
      "source": [
        "import bisect\n",
        "import collections\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Pad `sos` and `eos` to denote the beginning and end of each sentence.\n",
        "def _pad_sos_eos(corpus: list[list[str]], sos: str, eos: str):\n",
        "  padded_corpus = []\n",
        "  for sentence in corpus:\n",
        "    padded_sentence = sentence\n",
        "    if not sentence[0] == sos:\n",
        "      padded_sentence = [sos] + sentence\n",
        "    if not sentence[-1] == eos:\n",
        "      padded_sentence += [eos]\n",
        "    print(f'input sentence = {sentence}')\n",
        "    print(f'padded sentence = {padded_sentence}')\n",
        "    padded_corpus.append(padded_sentence)\n",
        "  return padded_corpus\n",
        "\n",
        "\n",
        "# Go through the sentences in the corpus and return the next bigram to caller.\n",
        "def _yield_bigrams(corpus: list[list[str]]):\n",
        "  for sentence in corpus:\n",
        "    for i in range(0, len(sentence) - 1):\n",
        "      yield (sentence[i], sentence[i + 1])\n",
        "\n",
        "\n",
        "# Implements a simple bi-gram model.\n",
        "class SimpleBigram:\n",
        "  def __init__(self):\n",
        "    self.vocab = []\n",
        "    self.counts = {}\n",
        "    self._sos = '<sos>'\n",
        "    self._eos = '<eos>'\n",
        "\n",
        "  # Create the model's vocabular from the training corpus.\n",
        "  # We first use a set to obtain unique words in the corpus. We then convert\n",
        "  # the set into a sorted list of words, from which we can deterministically\n",
        "  # retrieve a word: e.g. \"get the 3rd word in the list\".\n",
        "  def build_vocab(self, corpus: list[list[str]]):\n",
        "    vocab = set()\n",
        "    for sentence in corpus:\n",
        "      vocab.update(sentence)\n",
        "    self.vocab = sorted(list(vocab))\n",
        "    print(f'Built vocabulary = {self.vocab}')\n",
        "\n",
        "  # Count bigrams in the training corpus.\n",
        "  # We go through the corpus and increment the self.counts entries.\n",
        "  # self.counts[prev_word][next_word] holds the number of times the bi-gram\n",
        "  # (prev_word, next_word) occurs in the corpus.\n",
        "  # P(next_word | previous_word), counting (<prev>, <next>)\n",
        "  # self.counts[\"I\"]: keep counts of bigram thats starts with \"I\"\n",
        "  # self.counts[\"I\"][\"mango\"]: counts of bigram <I,mango>\n",
        "  def count_bigrams(self, corpus: list[list[str]]):\n",
        "    for word in self.vocab:\n",
        "      self.counts[word] = collections.Counter()\n",
        "\n",
        "    for prev_word, next_word in _yield_bigrams(corpus):\n",
        "      self.counts[prev_word][next_word] += 1\n",
        "\n",
        "  # Fit the training corpus to the bi-gram model.\n",
        "  # [[\"the\", \"sun\", \"is\", \"red\"],\n",
        "  #  [\"hello\", \"word\"]]\n",
        "  def fit(self, corpus: list[list[str]]):\n",
        "    padded_corpus = _pad_sos_eos(corpus, self._sos, self._eos)\n",
        "    self.build_vocab(padded_corpus)\n",
        "    self.count_bigrams(padded_corpus)\n",
        "\n",
        "  # Compute P(next_word | prev_word).\n",
        "  def p_next_word(self, next_word: str, prev_word: str) -> float:\n",
        "    if prev_word not in self.counts:\n",
        "      raise ValueError(f'{prev_word = } is oov')\n",
        "\n",
        "    n_total = sum(self.counts[prev_word].values())\n",
        "    p_next_word = self.counts[prev_word][next_word] / n_total\n",
        "    return p_next_word\n",
        "\n",
        "  # Generate next word, given a prev_word.\n",
        "  # For each word in the vocabulary, we compute P(<word> | prev_word).\n",
        "  # We then \"roll a dice\" to draw the next word, according to the computed next\n",
        "  # token probabilities.\n",
        "  # P(apple | context): deterministic\n",
        "  # context := context + apple|orange\n",
        "  # I like apple: maximize P(I | sos), maximize P(like | I), maximize P(apple | I like)\n",
        "  # groundtruth: P(I | sos) = 1, P(like | I) = 1, ...\n",
        "  def generate_next_word(self, prev_word: str) -> str:\n",
        "    next_word_probs = []\n",
        "    for next_word in self.vocab:\n",
        "      next_word_probs.append(self.p_next_word(next_word, prev_word))\n",
        "    print(f'Counts of bi-grams starting with {prev_word}: {self.counts[prev_word]}')\n",
        "    print(f'{prev_word = }. next word probalities = {dict((word, prob) for word, prob in zip(self.vocab, next_word_probs))}')\n",
        "    print()\n",
        "\n",
        "    next_word_id = np.nonzero(np.random.multinomial(1, next_word_probs))[0][0]\n",
        "    return self.vocab[next_word_id]\n",
        "\n",
        "  # Generate text, given a seed word. When seed word is None, consider\n",
        "  # seed_word = sos.\n",
        "  # We start from the seed word, and generate a next_word, as defined by\n",
        "  # `generate_next_word`. Then we will use next_word and the nex prev_word, to\n",
        "  # generate the next next word. We continue this process, until an eos token\n",
        "  # is generated - this is when we terminate the generation.\n",
        "  def generate_text(self, seed_word: str | None = None) -> list[str]:\n",
        "    seed_word = self._sos if seed_word is None else seed_word\n",
        "    result = [seed_word]\n",
        "    while result[-1] != self._eos:\n",
        "      next_word = self.generate_next_word(prev_word=result[-1])\n",
        "      result.append(next_word)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LPKLVtx4DsH",
        "outputId": "f724b52c-d210-4584-890a-b15ce0d2910e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input sentence = ['mango', 'is', 'yummy']\n",
            "padded sentence = ['<sos>', 'mango', 'is', 'yummy', '<eos>']\n",
            "input sentence = ['I', 'like', 'orange']\n",
            "padded sentence = ['<sos>', 'I', 'like', 'orange', '<eos>']\n",
            "input sentence = ['apple', 'sucks']\n",
            "padded sentence = ['<sos>', 'apple', 'sucks', '<eos>']\n",
            "input sentence = ['I', 'really', 'like', 'mango']\n",
            "padded sentence = ['<sos>', 'I', 'really', 'like', 'mango', '<eos>']\n",
            "Built vocabulary = ['<eos>', '<sos>', 'I', 'apple', 'is', 'like', 'mango', 'orange', 'really', 'sucks', 'yummy']\n"
          ]
        }
      ],
      "source": [
        "corpus = [['mango', 'is', 'yummy'],\n",
        "          ['I', 'like', 'orange'],\n",
        "          ['apple', 'sucks'],\n",
        "          ['I', 'really', 'like', 'mango']]\n",
        "\n",
        "simple_bigram = SimpleBigram()\n",
        "simple_bigram.fit(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgBhi7ZP7h0Z",
        "outputId": "5ace8869-794b-4037-c304-bcf7fb5b0927"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counts of bi-grams starting with <sos>: Counter({'I': 2, 'mango': 1, 'apple': 1})\n",
            "prev_word = '<sos>'. next word probalities = {'<eos>': 0.0, '<sos>': 0.0, 'I': 0.5, 'apple': 0.25, 'is': 0.0, 'like': 0.0, 'mango': 0.25, 'orange': 0.0, 'really': 0.0, 'sucks': 0.0, 'yummy': 0.0}\n",
            "\n",
            "Counts of bi-grams starting with I: Counter({'like': 1, 'really': 1})\n",
            "prev_word = 'I'. next word probalities = {'<eos>': 0.0, '<sos>': 0.0, 'I': 0.0, 'apple': 0.0, 'is': 0.0, 'like': 0.5, 'mango': 0.0, 'orange': 0.0, 'really': 0.5, 'sucks': 0.0, 'yummy': 0.0}\n",
            "\n",
            "Counts of bi-grams starting with like: Counter({'orange': 1, 'mango': 1})\n",
            "prev_word = 'like'. next word probalities = {'<eos>': 0.0, '<sos>': 0.0, 'I': 0.0, 'apple': 0.0, 'is': 0.0, 'like': 0.0, 'mango': 0.5, 'orange': 0.5, 'really': 0.0, 'sucks': 0.0, 'yummy': 0.0}\n",
            "\n",
            "Counts of bi-grams starting with mango: Counter({'is': 1, '<eos>': 1})\n",
            "prev_word = 'mango'. next word probalities = {'<eos>': 0.5, '<sos>': 0.0, 'I': 0.0, 'apple': 0.0, 'is': 0.5, 'like': 0.0, 'mango': 0.0, 'orange': 0.0, 'really': 0.0, 'sucks': 0.0, 'yummy': 0.0}\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<sos>', 'I', 'like', 'mango', '<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "simple_bigram.generate_text()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KOZtWXCNWTjY",
        "outputId": "f691cf1a-95e2-43f2-deb8-d03c9a539b54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Note: To load files correct, add the \"Module 6 : Deep Dive Into LLMs\" folder\n",
        "# as shortcut under \"MyDrive\".\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "assets_dir = '/content/drive/MyDrive/Module 6 : Deep Dive into LLMs - V2/Assignment and MCQs/datasets/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "eHUA1hixk5EN",
        "outputId": "9dde9651-01b2-4c01-f9c1-c48107d17a6b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review sentiment\n",
              "0  One of the other reviewers has mentioned that ...  positive\n",
              "1  A wonderful little production. <br /><br />The...  positive\n",
              "2  I thought this was a wonderful way to spend ti...  positive\n",
              "3  Basically there's a family where a little boy ...  negative\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d0a3a805-d169-461b-8c1b-18c27e8246ab\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d0a3a805-d169-461b-8c1b-18c27e8246ab')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d0a3a805-d169-461b-8c1b-18c27e8246ab button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d0a3a805-d169-461b-8c1b-18c27e8246ab');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-691bbfd7-30ae-482e-b848-ef7def9b4a6c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-691bbfd7-30ae-482e-b848-ef7def9b4a6c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-691bbfd7-30ae-482e-b848-ef7def9b4a6c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_reviews",
              "summary": "{\n  \"name\": \"df_reviews\",\n  \"rows\": 50000,\n  \"fields\": [\n    {\n      \"column\": \"review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 49582,\n        \"samples\": [\n          \"\\\"Soul Plane\\\" is a horrible attempt at comedy that only should appeal people with thick skulls, bloodshot eyes and furry pawns. <br /><br />The plot is not only incoherent but also non-existent, acting is mostly sub sub-par with a gang of highly moronic and dreadful characters thrown in for bad measure, jokes are often spotted miles ahead and almost never even a bit amusing. This movie lacks any structure and is full of racial stereotypes that must have seemed old even in the fifties, the only thing it really has going for it is some pretty ladies, but really, if you want that you can rent something from the \\\"Adult\\\" section. OK?<br /><br />I can hardly see anything here to recommend since you'll probably have a lot a better and productive time chasing rats with a sledgehammer or inventing waterproof teabags or whatever.<br /><br />2/10\",\n          \"Guest from the Future tells a fascinating story of time travel, friendship, battle of good and evil -- all with a small budget, child actors, and few special effects. Something for Spielberg and Lucas to learn from. ;) A sixth-grader Kolya \\\"Nick\\\" Gerasimov finds a time machine in the basement of a decrepit building and travels 100 years into the future. He discovers a near-perfect, utopian society where robots play guitars and write poetry, everyone is kind to each other and people enjoy everything technology has to offer. Alice is the daughter of a prominent scientist who invented a device called Mielophone that allows to read minds of humans and animals. The device can be put to both good and bad use, depending on whose hands it falls into. When two evil space pirates from Saturn who want to rule the universe attempt to steal Mielophone, it falls into the hands of 20th century school boy Nick. With the pirates hot on his tracks, he travels back to his time, followed by the pirates, and Alice. Chaos, confusion and funny situations follow as the luckless pirates try to blend in with the earthlings. Alice enrolls in the same school Nick goes to and demonstrates superhuman abilities in PE class. The catch is, Alice doesn't know what Nick looks like, while the pirates do. Also, the pirates are able to change their appearance and turn literally into anyone. (Hmm, I wonder if this is where James Cameron got the idea for Terminator...) Who gets to Nick -- and Mielophone -- first? Excellent plot, non-stop adventures, and great soundtrack. I wish Hollywood made kid movies like this one...\",\n          \"\\\"National Treasure\\\" (2004) is a thoroughly misguided hodge-podge of plot entanglements that borrow from nearly every cloak and dagger government conspiracy clich\\u00e9 that has ever been written. The film stars Nicholas Cage as Benjamin Franklin Gates (how precious is that, I ask you?); a seemingly normal fellow who, for no other reason than being of a lineage of like-minded misguided fortune hunters, decides to steal a 'national treasure' that has been hidden by the United States founding fathers. After a bit of subtext and background that plays laughably (unintentionally) like Indiana Jones meets The Patriot, the film degenerates into one misguided whimsy after another \\u0096 attempting to create a 'Stanley Goodspeed' regurgitation of Nicholas Cage and launch the whole convoluted mess forward with a series of high octane, but disconnected misadventures.<br /><br />The relevancy and logic to having George Washington and his motley crew of patriots burying a king's ransom someplace on native soil, and then, going through the meticulous plan of leaving clues scattered throughout U.S. currency art work, is something that director Jon Turteltaub never quite gets around to explaining. Couldn't Washington found better usage for such wealth during the start up of the country? Hence, we are left with a mystery built on top of an enigma that is already on shaky ground by the time Ben appoints himself the new custodian of this untold wealth. Ben's intentions are noble \\u0096 if confusing. He's set on protecting the treasure. For who and when?\\u0085your guess is as good as mine.<br /><br />But there are a few problems with Ben's crusade. First up, his friend, Ian Holmes (Sean Bean) decides that he can't wait for Ben to make up his mind about stealing the Declaration of Independence from the National Archives (oh, yeah \\u0096 brilliant idea!). Presumably, the back of that famous document holds the secret answer to the ultimate fortune. So Ian tries to kill Ben. The assassination attempt is, of course, unsuccessful, if overly melodramatic. It also affords Ben the opportunity to pick up, and pick on, the very sultry curator of the archives, Abigail Chase (Diane Kruger). She thinks Ben is clearly a nut \\u0096 at least at the beginning. But true to action/romance form, Abby's resolve melts quicker than you can say, \\\"is that the Hope Diamond?\\\" The film moves into full X-File-ish mode, as the FBI, mistakenly believing that Ben is behind the theft, retaliate in various benign ways that lead to a multi-layering of action sequences reminiscent of Mission Impossible meets The Fugitive. Honestly, don't those guys ever get 'intelligence' information that is correct? In the final analysis, \\\"National Treasure\\\" isn't great film making, so much as it's a patchwork rehash of tired old bits from other movies, woven together from scraps, the likes of which would make IL' Betsy Ross blush.<br /><br />The Buena Vista DVD delivers a far more generous treatment than this film is deserving of. The anamorphic widescreen picture exhibits a very smooth and finely detailed image with very rich colors, natural flesh tones, solid blacks and clean whites. The stylized image is also free of blemishes and digital enhancements. The audio is 5.1 and delivers a nice sonic boom to your side and rear speakers with intensity and realism. Extras include a host of promotional junket material that is rather deep and over the top in its explanation of how and why this film was made. If only, as an audience, we had had more clarification as to why Ben and co. were chasing after an illusive treasure, this might have been one good flick. Extras conclude with the theatrical trailer, audio commentary and deleted scenes. Not for the faint-hearted \\u0096 just the thick-headed.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"negative\",\n          \"positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "#@title Read IMDB movie review dataset.\n",
        "import pandas as pd\n",
        "\n",
        "df_reviews = pd.read_csv(os.path.join(assets_dir, 'IMDB_Dataset.csv'))\n",
        "df_reviews.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "UH7uLP4PeiF7",
        "outputId": "3bd5d37c-32da-4808-cb89-3a4330601c9f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "df_reviews.iloc[0].review"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "510-EA2n_UEc"
      },
      "source": [
        "### Train an bi-gram and a 4-gram model using IMDB movie review corpus\n",
        "\n",
        "In this section, we train n-gram models using the IMDB movie review dataset, and use the trained n-gram models to write moview reviews. We use the nltk library, which provides n-gram model training and data preprocessing funcionalities. Read more about nltk from [nltk documentation](https://www.nltk.org/index.html).\n",
        "\n",
        "We can observe that the n-gram models are not great moview review writers. They only care about the counts of n-grams, and have no understanding of gramma or meaning of words. They also have no intrinsic knowledge of any movies. The n-gram models also struggle with coherency: each word is generated based on only the previous few words, and different parts of a review often discuss unrelated movies/topics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7LX61xWkKV4",
        "outputId": "70874527-50df-45e8-dd0d-0eec19e47006"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qDwXc-nuoVD"
      },
      "source": [
        "Training data is constructed as follows:\n",
        "\n",
        "\n",
        "1.   Take the training corpus. For each text sequence (i.e. review), tokenize the sequence into words, and add start and end tokens.\n",
        "2.   Flatten all reviews into a big single string.\n",
        "3.   Create a stream of n-gram and the vocabulary from the flat review string. nltk uses `everygram` objects to create a generator which returns all unigram, bi-gram, .... k-gram (k is a argument)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SxjZsr_OlNec"
      },
      "outputs": [],
      "source": [
        "# Create training data and vocabulary from IMDB movie reviews.\n",
        "# Note that `padded_everygram_pipeline` returns generaters. We need to call\n",
        "# this function each time we train a model, since the training exhausts the\n",
        "# generator.\n",
        "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
        "\n",
        "def get_train_data_and_vocab():\n",
        "  all_reviews = df_reviews.review.to_list()\n",
        "  # Each review is broken into a list of tokens:\n",
        "  # [\"I like dog\", \"good movie\"] => [[\"I\", \"like\", \"dog\"], [\"good\", \"movie\"]]\n",
        "  all_reviews_tokens = [nltk.tokenize.word_tokenize(review, language='english', preserve_line=False)\n",
        "                        for review in all_reviews]\n",
        "  # Pad start and end token to each review:\n",
        "  # [[\"I\", \"like\", \"dog\"], [\"good\", \"movie\"]] => [\"<s>\", \"I\", \"like\", \"dog\", \"</s>\", \"<s>\", \"good\", \"movie\", \"</s>\"] (unigram stream)\n",
        "  train_grams, vocab = padded_everygram_pipeline(4, all_reviews_tokens)\n",
        "  return train_grams, vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A4LKKVjd6GCx"
      },
      "outputs": [],
      "source": [
        "from nltk.lm import MLE\n",
        "\n",
        "# Train an n-gram model using IMDB movie review dataset.\n",
        "def train_n_gram(n):\n",
        "  train_grams, vocab = get_train_data_and_vocab()\n",
        "  model = MLE(n)\n",
        "  model.fit(train_grams, vocab)\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "zLWm4R7y_p0V"
      },
      "outputs": [],
      "source": [
        "review_4_gram = train_n_gram(4)\n",
        "review_2_gram = train_n_gram(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XarFJnf5LjuG"
      },
      "source": [
        "### Generate movie reviews using the bi-gram and 4-gram models.\n",
        "\n",
        "We trained a bi-gram model and a 4-gram model below and now use them to generate movie reviews. For each model, we seed the generation with \"I\", and generate 3 different review.\n",
        "\n",
        "The bi-gram model has notably worse lucidity. Additionally, since both models are based purely on n-gram counts, the generated reviews lack coherence: different parts of the review tend to discuss different movies.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jenM7tV26U1E",
        "outputId": "36d401f6-d0cc-4f0f-acc9-31ec3dcc98a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "knew someone who saw Revenge of The Dorks . '' Perhaps the film could drag on forever and the scares are very subtle , not the Wolfman , or Lenny '' Of Mice and Men '' - an altogether different story. < br / > Spielberg is always put down for the money spent on them the numbers are well staged and electrifying . Prince is so tight that you are special in the same semester . We get lovable old grumpus Jonathan the prospector , his young brother is a bad movie but could n't make it seem boring\n",
            "'m not really one i 've seen in awhile ! Hopefully , I 'll give him a first name , but this stuff is happening right before your eyes , please do , you will not want to see an independent film . This looks like a high-end hotel room - probably because they are freely displayed . What we got was as good as the baddest of the bad guys are cardboard cut-outs who all sound like a very foolish organization . In reality , that 's right they never have anything approaching a normal conversation in all of\n",
            "was a kid . </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s>\n"
          ]
        }
      ],
      "source": [
        "for _ in range(3):\n",
        "  new_review = review_4_gram.generate(num_words=100, text_seed='I')\n",
        "  print(' '.join(new_review))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XwCyhqRHGO4O",
        "outputId": "7c5cd779-dfab-432e-8ddb-8cd81f4be7d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "did it 's teeth . If you busy trying not much better movies so beautiful woman who are for book . As the amount of us guessing for their parts feature is quite brilliant about the songs as a charming southerner gave a better trimmed otherwise it should be argued that target and crosses over to experience but he joins the Robocop cyborg , it on this cruddy low-brow magician turned out of America would 've seen . Director Sasaki ) , not very boring movies ' Ford Coppola 's parts : a single email , are the need .\n",
            "like Verhoeven look at the 80 's the continuity of the trailer as one of the philosophy into a wash my reviews of just about a motorcycle race against the movie I 'd be it 's car , while its over-long one of the daughter ( a comedy , as , it . The plot does sleazy exploitation films , folks could hit the word THEY looked like people who demands . At least terrifying if you 're guaranteed commercial values as far the Russian film is . Sheridan and suspense low : from Le Blanc has a few and\n",
            "should have Titles in addition of attention there . < br / > < br / > When I do roll. < br / > < br / > < br / > < br / > * * Friday the match , first 5 favourite comedy that it ... Python crew ( Pamela Britton and squirts copious amounts to him to hit it was disappointed and some cool carrying out . Well , led us sad , and blowing it makes the sometimes you can see the very well as a ' , but as you are the novel\n"
          ]
        }
      ],
      "source": [
        "for _ in range(3):\n",
        "  new_review = review_2_gram.generate(num_words=100, text_seed='I')\n",
        "  print(' '.join(new_review))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}